
### å¸¸è§é—®é¢˜

#### Q1: æ˜¾å­˜ä¸è¶³æ€ä¹ˆåŠï¼Ÿ
- å‡å° `BATCH_SIZE` åˆ° 1
- é™ä½ `MAX_LEN` åˆ° 256
- å¯ç”¨æ¢¯åº¦æ£€æŸ¥ç‚¹

#### Q2: è®­ç»ƒé€Ÿåº¦å¤ªæ…¢ï¼Ÿ
- å¢åŠ  `GRAD_ACCUM` å€¼
- ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- å‡å°‘è®­ç»ƒè½®æ•°

#### Q3: æ¨¡å‹è´¨é‡ä¸ä½³ï¼Ÿ
- æ£€æŸ¥è®­ç»ƒæ•°æ®è´¨é‡
- å¢åŠ è®­ç»ƒè½®æ•°
- è°ƒæ•´å­¦ä¹ ç‡

### é«˜çº§é…ç½®

#### è‡ªå®šä¹‰è®­ç»ƒå‚æ•°
ç¼–è¾‘è®­ç»ƒè„šæœ¬ä¸­çš„å‚æ•°ï¼š
```python
# train_sft.py
BATCH_SIZE = 2                  # æ‰¹æ¬¡å¤§å°
GRAD_ACCUM = 4                  # æ¢¯åº¦ç´¯ç§¯
EPOCHS = 2                      # è®­ç»ƒè½®æ•°
MAX_LEN = 1024                  # æœ€å¤§é•¿åº¦
LR = 1e-5                       # å­¦ä¹ ç‡
```

#### å¤šGPUè®­ç»ƒ
```bash
export CUDA_VISIBLE_DEVICES=0,1,2,3
accelerate launch train_sft.py
```

### æ¨¡å‹è¯„ä¼°

#### è‡ªåŠ¨è¯„ä¼°
è®­ç»ƒè„šæœ¬ä¼šè‡ªåŠ¨è®¡ç®—ï¼š
- å›°æƒ‘åº¦ (Perplexity)
- å‡†ç¡®ç‡ (Accuracy)
- F1åˆ†æ•°

#### äººå·¥è¯„ä¼°
å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼æµ‹è¯•æ¨¡å‹ï¼š
```python
from transformers import AutoTokenizer, AutoModelForCausalLM

model = AutoModelForCausalLM.from_pretrained("./sft_model")
tokenizer = AutoTokenizer.from_pretrained("./sft_model")

prompt = "ç”¨Pythonå®ç°å¿«é€Ÿæ’åºç®—æ³•"
inputs = tokenizer(prompt, return_tensors="pt")
outputs = model.generate(**inputs, max_length=512)
print(tokenizer.decode(outputs[0]))
```

### éƒ¨ç½²ä½¿ç”¨

#### æ¨¡å‹åŠ è½½
```python
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹
model_path = "./ppo_model"  # æˆ– "./sft_model"
tokenizer = AutoTokenizer.from_pretrained(model_path)
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.bfloat16,
    device_map="auto"
)
```

#### ä»£ç ç”Ÿæˆ
```python
def generate_code(prompt, max_length=512):
    inputs = tokenizer(prompt, return_tensors="pt")
    outputs = model.generate(
        **inputs,
        max_length=max_length,
        temperature=0.7,
        do_sample=True,
        top_p=0.95
    )
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

# ä½¿ç”¨ç¤ºä¾‹
code = generate_code("ç”¨Pythonå®ç°äºŒå‰æ ‘éå†")
print(code)
```

### æœ€ä½³å®è·µ

1. **æ•°æ®è´¨é‡**: ç¡®ä¿è®­ç»ƒæ•°æ®å‡†ç¡®ã€å¤šæ ·
2. **é€æ­¥è®­ç»ƒ**: å…ˆSFTå†RMæœ€åPPO
3. **ç›‘æ§æŒ‡æ ‡**: å¯†åˆ‡å…³æ³¨è®­ç»ƒæŸå¤±å’Œè¯„ä¼°æŒ‡æ ‡
4. **ä¿å­˜æ£€æŸ¥ç‚¹**: å®šæœŸä¿å­˜æ¨¡å‹çŠ¶æ€
5. **ç¯å¢ƒéš”ç¦»**: ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒé¿å…ä¾èµ–å†²çª

### æŠ€æœ¯æ”¯æŒ

å¦‚é‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š
- CUDAå’ŒPyTorchç‰ˆæœ¬å…¼å®¹æ€§
- æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§
- æ•°æ®æ ¼å¼æ­£ç¡®æ€§
- æ˜¾å­˜ä½¿ç”¨æƒ…å†µ

---

ç¥ä½ è®­ç»ƒé¡ºåˆ©ï¼ğŸš€
